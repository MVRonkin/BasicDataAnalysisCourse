{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25114698-7698-4558-b21b-f8272cfed4c1",
   "metadata": {},
   "source": [
    "# Машинное обучение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c81434-1066-4d04-a0c6-1a7c754fe91a",
   "metadata": {},
   "source": [
    "## Одно из [определений МО](https://habr.com/ru/companies/ods/articles/322534/)\n",
    "\n",
    "Классическое, общее [определение машинного обучения (МО)](https://www.deeplearningbook.org/contents/ml.html) звучит так ([T. Mitchell \"Machine learning\", 1997](https://www.cs.cmu.edu/~tom/files/MachineLearningTomMitchell.pdf)):\n",
    "\n",
    "<blockquote>\n",
    "Definition: A computer program is said to learn from experience E with respectto some class of tasks T and performance measure P, if its performance at tasks inT, as measured by P, improves with experience E.\n",
    "</blockquote> \n",
    "\n",
    "__или другими словами__:\n",
    "<blockquote>\n",
    "Компьютерная программа обучается при решении какой-то задачи из класса $T$, если ее производительность, согласно метрике $P$, улучшается при накоплении опыта $E$.\n",
    "</blockquote>\n",
    "\n",
    "Далее в разных сценариях под $T$, $P$, и $E$ подразумеваются совершенно разные вещи. \n",
    "\n",
    "Среди самых популярных __задач $T$__ в машинном обучении:\n",
    "* классификация – отнесение объекта к одной из категорий на основании его признаков\n",
    "* регрессия – прогнозирование количественного признака объекта на основании прочих его признаков\n",
    "* кластеризация – разбиение множества объектов на группы на основании признаков этих объектов так, чтобы внутри групп объекты были похожи между собой, а вне одной группы – менее похожи\n",
    "* детекция аномалий – поиск объектов, \"сильно непохожих\" на все остальные в выборке либо на какую-то группу объектов\n",
    "* и много других, более специфичных. \n",
    "\n",
    "Под __опытом $E$__ понимаются __данные__. Данные и в зависимости от этого алгоритмы машинного обучения могут быть поделены на те, что обучаются с учителем и без учителя (__supervised & unsupervised learning__). В задачах обучения без учителя имеется выборка, состоящая из объектов, описываемых набором признаков. В задачах обучения с учителем вдобавок к этому для каждого объекта некоторой выборки, называемой обучающей, известен целевой признак – по сути это то, что хотелось бы прогнозировать для прочих объектов, не из обучающей выборки.\n",
    "\n",
    "\n",
    "_Пример_\n",
    "\n",
    "Задачи классификации и регрессии – это задачи обучения с учителем. В качестве примера будем представлять задачу кредитного скоринга: на основе накопленных кредитной организацией данных о своих клиентах хочется прогнозировать невозврат кредита. Здесь для алгоритма опыт $E$ – это имеющаяся обучающая выборка: набор объектов (людей), каждый из которых характеризуется набором признаков (таких как возраст, зарплата, тип кредита, невозвраты в прошлом и т.д.), а также целевым признаком. Если этот целевой признак – просто факт невозврата кредита ($1$ или $0$, т.е. банк знает о своих клиентах, кто вернул кредит, а кто – нет), то это задача (бинарной) классификации. Если известно, на сколько по времени клиент затянул с возвратом кредита и хочется то же самое прогнозировать для новых клиентов, то это будет задачей регрессии.\n",
    "\n",
    "\n",
    "Наконец, третья абстракция в определении машинного обучения – это __метрика оценки производительности алгоритма P__. Такие метрики различаются для разных задач и алгоритмов. Cамая простая метрика качества алгоритма, решающего задачу классификации – это доля правильных ответов (_accuracy_, не называйте ее точностью, этот перевод зарезервирован под другую метрику, _precision_) – то есть попросту доля верных прогнозов алгоритма на тестовой выборке.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e47a1-dfd4-4c7c-a8d1-38a77455f696",
   "metadata": {},
   "source": [
    "## Фреймворк Scikit-learn\n",
    "\n",
    "[__Scikit-learn (sklearn)__](https://scikit-learn.org/stable/) — [это](https://blog.skillfactory.ru/glossary/scikit-learn/) один из наиболее широко используемых пакетов Python для Data Science и Machine Learning. Он содержит функции и алгоритмы для машинного обучения: классификации, прогнозирования или разбивки данных на группы.\n",
    "\n",
    "[Sklearn долгое время (с 2007) остаётся](https://habr.com/ru/companies/netologyru/articles/911216/) в стеке любого специалиста по анализу данных и ИИ, потому что хорошо закрывает типовые задачи ML: классификацию, регрессию, отбор признаков, масштабирование, кросс-валидацию. Когда данные уже лежат в таблице, а нужно быстро запустить задачу, с ней проще всего собрать работающий прототип. \n",
    "\n",
    "Все методы обработки данных, реализованные __scikit-learn__ реализуют единый и предсказуемый интерфейс, основанный на методах `.fit()`, `.predict()` и `.transform()`. Этот подход стал де-факто стандартом и был подхвачен другими библиотеками, такими как `LightGBM` и `XGBoost`/`CatBoost`, а также совеместим со многими библиотеками анализа данных, например `Optuna`. Благодаря этому инструменты анализа данных хорошо сочетаются друг с другом, а модели можно заменять без необходимости переписывать весь код.\n",
    "\n",
    "Библиотека `sklearn` хорошо [сочетается ](https://habr.com/ru/companies/netologyru/articles/911216/) с остальными инструментами `Python`. Она работает с массивами `numpy` и датафреймами `pandas`, строит графики через `matplotlib`, сохраняет модели с помощью `joblib`.\n",
    "\n",
    "Вводный гайд по основным функциям библиотеки может быть найден в [официальной документации](https://scikit-learn.org/stable/user_guide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fefa6a-dc97-4798-aa81-1e2f49531896",
   "metadata": {},
   "source": [
    "## Запуск библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b40e801-1003-4f09-a2a2-83d8e1da1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import sklearn\n",
    "except:\n",
    "    %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9a5ac7-0f25-4fb6-957e-ee86c85de90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9750c1-ac69-404d-ae67-398a5a63baf5",
   "metadata": {},
   "source": [
    "Дальше можно убедиться, что всё работает корректно: библиотека загружается, данные читаются, модель обучается. Для этого запустите простой пример на встроенном датасете `iris`.\n",
    "\n",
    "Подключим четыре модуля:\n",
    "\n",
    "* `datasets` — встроенные датасеты для тестов;\n",
    "* `linear_model` — простые модели вроде логистической регрессии;\n",
    "* `model_selection` — разбиение данных и кросс-валидация;\n",
    "* `metrics` — функции для оценки качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24d62d4-b810-48cd-b678-c3debf396972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics, model_selection\n",
    "\n",
    "# Загружаем данные\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7a3b1-ffab-45aa-a047-75b93016a7c0",
   "metadata": {},
   "source": [
    "Функция `train_test_split` просто случайно выбирает, какие объекты пойдут в обучение, а какие — в тест. Но поведение этой функции можно настраивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e5efe6-ca9f-485f-a91b-4bf6b1d2b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Разбиваем на обучение и тест\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577953f-5a06-4cf4-89c3-4426031e68f5",
   "metadata": {},
   "source": [
    "У `sklearn` единый подход ко всем моделям: сначала данные передают в `fit`, потом получают предсказания через `predict`, а дальше оценивают результат — с помощью `score` или функций из `metrics`. Эта схема работает одинаково для разных алгоритмов, поэтому после первого примера становится понятно, как работает вся библиотека.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a921f7-76f1-48df-aa6f-c16096588c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "model = linear_model.LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Считаем метрику\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9213cd-4048-47f3-9977-d575273725f1",
   "metadata": {},
   "source": [
    "И так, в примере загружается встроенный набор данных `iris`, где каждый объект — это параметры цветка, а цель — определить его класс. Данные делятся на обучающую и тестовую выборки: модель учится на одной части (`fit`) и проверяется на другой (`predict`). После этого считается метрика качества — точность (`accuracy`), то есть доля правильных ответов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e464993-bb47-4e17-9641-88371503358c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
